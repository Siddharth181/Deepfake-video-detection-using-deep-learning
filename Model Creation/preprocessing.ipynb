{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nMI7CYxcyiUB"
      },
      "source": [
        "Before running the file Upload all your data set on your goole drive in a zip format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YjtnZQkTu6tX"
      },
      "outputs": [],
      "source": [
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f4y_fGlmur4v"
      },
      "outputs": [],
      "source": [
        "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
        "#download and unzip the data from google drive Colab environment\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "#use only file id of the link\n",
        "#Example\n",
        "#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n",
        "url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n",
        "gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1f40EeRuvAkO"
      },
      "outputs": [],
      "source": [
        "#To get the average frame count \n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "#change the path accordingly\n",
        "video_files =  glob.glob('/content/drive/MyDrive/Dataset*.mp4')\n",
        "#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n",
        "#video_files += video_files1\n",
        "frame_count = []\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames\" , frame_count)\n",
        "print(\"Total number of videos: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U92Ovn3JvV52"
      },
      "outputs": [],
      "source": [
        "# to extract frame\n",
        "def frame_extract(path):\n",
        "  vidObj = cv2.VideoCapture(path) \n",
        "  success = 1\n",
        "  while success:\n",
        "      success, image = vidObj.read()\n",
        "      if success:\n",
        "          yield image\n",
        "!pip3 install face_recognition\n",
        "!mkdir '/content/drive/My Drive/Face_only_data'\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "from tqdm.autonotebook import tqdm\n",
        "# process the frames\n",
        "def create_face_videos(path_list,out_dir):\n",
        "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
        "  print(\"No of videos already present \" , len(already_present_count))\n",
        "  for path in tqdm(path_list):\n",
        "    out_path = os.path.join(out_dir,path.split('/')[-1])\n",
        "    file_exists = glob.glob(out_path)\n",
        "    if(len(file_exists) != 0):\n",
        "      print(\"File Already exists: \" , out_path)\n",
        "      continue\n",
        "    frames = []\n",
        "    flag = 0\n",
        "    face_all = []\n",
        "    frames1 = []\n",
        "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
        "    for idx,frame in enumerate(frame_extract(path)):\n",
        "      #if(idx % 3 == 0):\n",
        "      if(idx <= 150):\n",
        "        frames.append(frame)\n",
        "        if(len(frames) == 4):\n",
        "          faces = face_recognition.batch_face_locations(frames)\n",
        "          for i,face in enumerate(faces):\n",
        "            if(len(face) != 0):\n",
        "              top,right,bottom,left = face[0]\n",
        "            try:\n",
        "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
        "            except:\n",
        "              pass\n",
        "          frames = []\n",
        "    try:\n",
        "      del top,right,bottom,left\n",
        "    except:\n",
        "      pass\n",
        "    out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sF5qiWGLvei-"
      },
      "outputs": [],
      "source": [
        "create_face_videos(video_files,'/content/drive/My Drive/Face_only_data/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
